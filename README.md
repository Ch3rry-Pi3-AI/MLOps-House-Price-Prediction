Perfect ğŸ‘Œ â€” hereâ€™s the next stageâ€™s **README**, adapted for your **deployment branch**.
It keeps the same professional tone and structure as your earlier stages while introducing Docker, FastAPI, Streamlit, and Docker Compose integration.



# **Model Deployment Stage**

This branch extends the **MLOps House Price Prediction** project by implementing the **model deployment pipeline**.
It introduces a full deployment stack built with **FastAPI** (for inference) and **Streamlit** (for the UI), both containerised using **Docker**, and orchestrated together with **Docker Compose**.

This stage completes the MLOps lifecycle â€” transforming trained models and preprocessing pipelines into live, user-facing services that can be built, run, and published anywhere.



## **Project Structure**

```
mlops-house-price-prediction/
â”œâ”€â”€ .venv/
â”œâ”€â”€ .github/
â”œâ”€â”€ data/
â”œâ”€â”€ models/
â”œâ”€â”€ notebooks/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ api/                                # ğŸš€ NEW: FastAPI inference service
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ inference.py                    #   Loads model + preprocessor, defines predict()
â”‚   â”‚   â”œâ”€â”€ main.py                         #   FastAPI entrypoint and routing
â”‚   â”‚   â”œâ”€â”€ schemas.py                      #   Pydantic request/response models
â”‚   â”‚   â””â”€â”€ requirements.txt                #   FastAPI + Uvicorn dependencies
â”‚   â”œâ”€â”€ data/
â”œâ”€â”€ streamlit_app/                          # ğŸš€ NEW: Streamlit front-end
â”‚   â”œâ”€â”€ app.py                              #   Web UI calling the FastAPI backend
â”‚   â”œâ”€â”€ requirements.txt                    #   Streamlit + Requests dependencies
â”‚   â””â”€â”€ Dockerfile                          #   Streamlit container definition
â”œâ”€â”€ Dockerfile                              # ğŸš€ NEW: FastAPI container definition
â”œâ”€â”€ docker-compose.yaml                     # ğŸš€ NEW: Multi-service orchestration (FastAPI + Streamlit)
â”œâ”€â”€ tasks.py
â”œâ”€â”€ README.md
â””â”€â”€ uv.lock
```

> Note: Any `.venv/` directory remains ignored and should not be committed.



## **Module Overview**

### ğŸ§  `src/api/` â€” FastAPI Inference Service

* Loads the trained model (`house_price_model.pkl`) and preprocessor.
* Exposes two routes:

  * **`/health`** â€” simple status check.
  * **`/predict`** â€” accepts JSON matching `HousePredictionRequest`, returns predicted price.
* Runs via **Uvicorn** in Docker on port `8000`.

### ğŸ¨ `streamlit_app/` â€” Streamlit Frontend

* Provides an interactive dashboard for user input.
* Calls the FastAPI backend using the `API_URL` environment variable (e.g. `http://fastapi:8000`).
* Displays predicted price, confidence interval, and feature importance.
* Runs via **Streamlit** in Docker on port `8501`.



## **Docker & Compose Overview**

### ğŸ§© Dockerfiles

* **Root `Dockerfile`** â†’ builds FastAPI backend.
* **`streamlit_app/Dockerfile`** â†’ builds Streamlit frontend.

### âš™ï¸ `docker-compose.yaml`

Defines both containers and their networking:

```yaml
services:
  fastapi:
    build: .
    ports: ["8000:8000"]

  streamlit:
    build: ./streamlit_app
    ports: ["8501:8501"]
    environment:
      API_URL: http://fastapi:8000
    depends_on:
      - fastapi
```

Docker Compose automatically links the two containers, so the Streamlit UI can reach the FastAPI service via its hostname `fastapi`.



## **Build and Run the Application**

### ğŸ—ï¸ Build both images

```bash
docker compose build
```

### ğŸš€ Run the full stack

```bash
docker compose up
# or detached:
docker compose up -d
```

### ğŸŒ Access the apps

| Service       | URL                                                      |
| - | -- |
| **FastAPI**   | [http://localhost:8000/docs](http://localhost:8000/docs) |
| **Streamlit** | [http://localhost:8501](http://localhost:8501)           |



## **Testing the FastAPI Endpoint**

### âœ… Health check

```bash
curl http://localhost:8000/health
```

### ğŸ§  Prediction request

```bash
curl -X POST "http://localhost:8000/predict" \
     -H "Content-Type: application/json" \
     -d '{"sqft":2000,"bedrooms":3,"bathrooms":2,"year_built":2010,"condition":"Good"}'
```

Expected response:

```json
{"predicted_price": 354820.45, "currency": "USD"}
```



## **Publishing to Docker Hub**

### 1ï¸âƒ£ Log in

```bash
docker login
# username: ch3rrypi3
```

### 2ï¸âƒ£ Push images

```bash
docker push ch3rrypi3/fastapi:dev
docker push ch3rrypi3/streamlit:dev
```

### 3ï¸âƒ£ Verify

Check your repositories at
ğŸ‘‰ [https://hub.docker.com/repositories/ch3rrypi3](https://hub.docker.com/repositories/ch3rrypi3)



## **Useful Docker Commands**

| Purpose                                 | Command                                   |
|  | -- |
| List running containers                 | `docker ps`                               |
| List all containers (including stopped) | `docker ps -a`                            |
| Stop containers                         | `docker compose down`                     |
| Remove all containers, images, networks | `docker system prune -a`                  |
| View image list                         | `docker images`                           |
| View logs (live)                        | `docker compose logs -f`                  |
| Build single image                      | `docker build -t ch3rrypi3/fastapi:dev .` |
| Push image to Docker Hub                | `docker push ch3rrypi3/fastapi:dev`       |



## âœ… Summary

With this stage, the project now delivers a **fully containerised, end-to-end ML application**:

* **FastAPI backend** for real-time inference.
* **Streamlit frontend** for an interactive UI.
* **Docker and Docker Compose** for seamless local orchestration.
* **Docker Hub** integration for image distribution and versioning.

The full MLOps lifecycle is now complete â€” from data ingestion and feature engineering to model training, deployment, and interactive visualisation. ğŸš€